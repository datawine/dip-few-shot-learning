# 数图大作业报告

### 计52 周京汉 2015011245

## 问题概述

本次大作业的具体任务为：在一个已经训练好了的1000类的网络，及其每个类别几十个样本所输出的fc7层的输出和其对应的labels等数据已知的情况下，给50个新的类别，每个类别给10张图片用来训练，最终得出对于新的类别的区分的网络。

这个问题是典型的few-shot问题，由少量的训练集得出正确率比较高的预测模型。我们在阅读文献之后，尝试了各种基础做法与尝试。我在其中主要的任务是完成分类器类型的方法的研究与代码书写调参等。

## 文献阅读

在小组分工当中，我阅读的是第二篇文献，《Learning to Compare: Relation Network for Few-Shot Learning》这是一篇应用了`relation network`的思想来进行few-shot任务完成的。其最主要的思想如下图：

![](/Users/mac/Desktop/university/CST/1718Spring/6_数字图像处理/hw/2/dip-few-shot-learning/report/zjh_1.jpeg)

其中，左边5幅图是用于训练的训练集，底下那张是用来测试的。在训练之后，会生成一张网络，即为中间的“embedding module”，随后用其计算最新的测试集图片，得到新的特性，再与原来的特性进行对比，即为“relaton module”，最终得到一个值，再讲这个值与之前生成的relation score相对比，最近的一个就是我们最终所要的分类。

我认为，这个思想，更多的是像一个分类器，用原有的模型对其进行分类，然后进行操作对比等，最终得出一个代表相对位置的值，来进行分类。

## 创新思路

因此，在此之上，我的基本方法是：应用Alexnet的训练好的模型作为基础模型，用新的图片作为训练集进行输入，然后会得到相应的网络的fc7输出，然后应用之前得到的fc7的值进行一些关联的运算，从原来训练好的模型输出的fc7当中得到更多的相似点，从而来实现更好的分类器。我们使用前8张图片进行训练，后两张图片进行验证，作为验证集。

### 点乘

首先我们想到的是用点乘的方法来获得原来的fc7当中的类型的特征。应用方法是用（63994，4096）的向量乘（4096，1），得到了（63994，1）的向量，然后用这个向量作为分类用的向量。

但是这种方法在实际应用中效果不好，虽然向量长度很长，但是实际上并不能将其新的特征展示出来，因此正确率并不能上升。

### 对1000类特征进行取平均

在点乘失败之后，我们认为，每个类不同数量的fc7的值会使其权重不一样，因此我将其进行预处理，进行平均处理，因此得到一个（1000，4096）的向量，然后再进行点乘操作，得到了（1000，1）的向量，用作分类。

这种方法在实际中对SVM有较好的提升，但是对于linearSVM起反作用。对于SVM的略微提升并不能使其超过linearSVM。

### 获得相似的fc7

在尝试了取平均之后，我认为需要将其中最类似的fc7进行提取，来更集中的获得他们的相似性。我用欧式距离来表示它们之间的相似度，欧式距离越小，相似度就越大。然后我根据其相似度对其进行排序，获得了其中的5个最相似的类，用加权平均的方式对其进行平均获得了一个最相似的（4096，1）的向量和一个（5，4096）的向量。

我对于得到的向量进行了点乘（得到（5，1）向量），卷积（same模式）得到（4096，1）向量，操作，其效果一般，没有得到显著提升，其中卷积模式也是只能小幅的提升SVM的准确率，未能提升linearSVM的准确率。对于SVM的略微提升并不能使其超过linearSVM。

### 应用normalization在摒除极端情况

在以上考虑的基础之上，我认为可以通过normalization的方法让其变的更加的紧凑，这样的话就不会出现极端的情况下导致整个分类器被拉偏的情况了。

因此我在一下位置尝试了normalization：取1000个平均后，点乘计算出向量后，和计算出最终进入分类器的向量之后对其进行normalize。normalization对于SVM的效果很好，最多可以使其与linearSVM持平，可以在验证集上达到最高的74%的正确率。

## 个人贡献

我在我们的创新思路的基础之上进行了尝试，分别尝试了knn，SVM，linearSVM和adaboost这几种不同的分类器。其中在以上各种方法综合中，最好的分别可以在验证集上达到64%，74%，74%和73%的准确率，因此可以看出，对于当前的分类任务，使用knn的效果远不如后三种的效果好。因此，在最终的提交版本中，我们采用了后三种方法作为了自己的最终的预测集合的得出的依据。

